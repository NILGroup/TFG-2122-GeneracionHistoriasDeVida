{"cells":[{"cell_type":"markdown","metadata":{"id":"d0P5TfX63YpE"},"source":["# Ajuste de T5 bajo WEBNLG"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":424,"status":"ok","timestamp":1653833175056,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"9qSX5CsixMSw","outputId":"b01bdaa7-f6af-489b-8b4d-39ba59fc18de"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla T4 (UUID: GPU-ec9b2da7-3f53-04f1-b264-7c8ab59a2dbb)\n"]}],"source":["# Número de GPUs y modelo\n","!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":597,"status":"ok","timestamp":1653833176183,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"w6-TicY3WcV-","outputId":"8a7b460d-0320-4c4b-a2ee-429c4385eaf9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun May 29 14:06:15 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   77C    P0    34W /  70W |   2344MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"sf1uUqSEKKgk"},"source":["## Instalación de las bibliotecas necesarias\n","\n","\n","En nuetro caso vamos a utilizar las bibliotecas Transformer de HuggingFace y SentencePiece para el tokenizador T5. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25135,"status":"ok","timestamp":1653837830290,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"A6ki1-m-5UUA","outputId":"eef18263-1eab-4430-8369-9862d1cc399a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 62.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 42.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 4.4 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 5.0 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch_lightning\n","  Downloading pytorch_lightning-1.6.3-py3-none-any.whl (584 kB)\n","\u001b[K     |████████████████████████████████| 584 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.64.0)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.21.6)\n","Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.11.0+cu113)\n","Collecting torchmetrics>=0.4.1\n","  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)\n","\u001b[K     |████████████████████████████████| 409 kB 53.5 MB/s \n","\u001b[?25hCollecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 53.0 MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.8.0)\n","Collecting pyDeprecate<0.4.0,>=0.3.1\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (6.0)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.2.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 41.7 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.1)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.17.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.7)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.46.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2022.5.18.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.2.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.4.0)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 65.2 MB/s \n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 3.4 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.12)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 52.5 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, pyDeprecate, fsspec, aiohttp, torchmetrics, pytorch-lightning\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.5.0 multidict-6.0.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.3 torchmetrics-0.8.2 yarl-1.7.2\n"]}],"source":["!pip install transformers\n","!pip install sentencepiece\n","!pip install pytorch_lightning"]},{"cell_type":"markdown","metadata":{"id":"Q5kRBZf_NRi1"},"source":["A continuación importamos los módulos y bibliiotecas que utilizaremos durante el ajuste del modelo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CB6rH4GenWpN"},"outputs":[],"source":["import pandas as pd\n","import os\n","import torch\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","from transformers.optimization import  Adafactor \n","import time\n","\n","import tensorflow as tf\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"-aWMq3DOKl34"},"source":["## Carga de la base de datos WEBNLG\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GRd4ACheFVnN"},"outputs":[],"source":["train_df = pd.read_csv(\"Modelo T5 Final/Dataset/webNLG2020_train_cleaned.csv\")\n","test_df = pd.read_csv(\"Modelo T5 Final/Dataset/webNLG2020_test_cleaned.csv\")\n","test_train_df = pd.read_csv(\"Modelo T5 Final/Dataset/webNLG2020_testtrain_cleaned.csv\")"]},{"cell_type":"markdown","metadata":{"id":"D2KpBLyhNrAW"},"source":["Eliminamos la primera columna que indica la posición del ejemplo en el conjunto original ya que no nos va a hacer falta."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AtRN2Z92Fpll"},"outputs":[],"source":["train_df = train_df.drop(['Unnamed: 0'], axis=1)\n","test_df = test_df.drop(['Unnamed: 0'], axis=1)\n","test_train_df = test_train_df.drop(['Unnamed: 0'], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":984,"status":"ok","timestamp":1653813127688,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"4K3oyiOWuG5D","outputId":"f3cfdfa5-4fed-43a6-dc64-b9e7faf13c90"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-969c60f2-56bf-4864-84e9-631de0f37d62\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input_text</th>\n","      <th>target_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Acharya Institute of Technology | city | Banga...</td>\n","      <td>The Acharya Institute of Technology in Karnata...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11th Mississippi Infantry Monument | country |...</td>\n","      <td>The 11th Mississippi Infantry monument is loca...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A-Rosa Luna | ship displacement | 1850.0 (tonn...</td>\n","      <td>The A-Rosa Luna was ordered on 22 January 2004...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>United Kingdom | leader | Elizabeth II</td>\n","      <td>Elizabeth II is the head of state in the Unite...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AIDAluna | owner | AIDA Cruises &amp;&amp; AIDAluna | ...</td>\n","      <td>AIDA Cruises own the AIDAluna which was built ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>35365</th>\n","      <td>Blockbuster (comicsCharacter) | creator | Gard...</td>\n","      <td>The comic book character Blockbuster was creat...</td>\n","    </tr>\n","    <tr>\n","      <th>35366</th>\n","      <td>Allama Iqbal International Airport | location ...</td>\n","      <td>The Allama Iqbal International Airport is loca...</td>\n","    </tr>\n","    <tr>\n","      <th>35367</th>\n","      <td>Bacon Explosion | country | United States &amp;&amp; U...</td>\n","      <td>Bacon Explosion comes from the United States w...</td>\n","    </tr>\n","    <tr>\n","      <th>35368</th>\n","      <td>Turkey | leader | Ahmet Davutoğlu &amp;&amp; Turkey | ...</td>\n","      <td>The capital of Turkey is Ankara , although the...</td>\n","    </tr>\n","    <tr>\n","      <th>35369</th>\n","      <td>108 St Georges Terrace | location | Perth &amp;&amp; P...</td>\n","      <td>108 St . Georges Terrace , with 50 floors , is...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>35370 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-969c60f2-56bf-4864-84e9-631de0f37d62')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-969c60f2-56bf-4864-84e9-631de0f37d62 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-969c60f2-56bf-4864-84e9-631de0f37d62');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                              input_text  \\\n","0      Acharya Institute of Technology | city | Banga...   \n","1      11th Mississippi Infantry Monument | country |...   \n","2      A-Rosa Luna | ship displacement | 1850.0 (tonn...   \n","3                 United Kingdom | leader | Elizabeth II   \n","4      AIDAluna | owner | AIDA Cruises && AIDAluna | ...   \n","...                                                  ...   \n","35365  Blockbuster (comicsCharacter) | creator | Gard...   \n","35366  Allama Iqbal International Airport | location ...   \n","35367  Bacon Explosion | country | United States && U...   \n","35368  Turkey | leader | Ahmet Davutoğlu && Turkey | ...   \n","35369  108 St Georges Terrace | location | Perth && P...   \n","\n","                                             target_text  \n","0      The Acharya Institute of Technology in Karnata...  \n","1      The 11th Mississippi Infantry monument is loca...  \n","2      The A-Rosa Luna was ordered on 22 January 2004...  \n","3      Elizabeth II is the head of state in the Unite...  \n","4      AIDA Cruises own the AIDAluna which was built ...  \n","...                                                  ...  \n","35365  The comic book character Blockbuster was creat...  \n","35366  The Allama Iqbal International Airport is loca...  \n","35367  Bacon Explosion comes from the United States w...  \n","35368  The capital of Turkey is Ankara , although the...  \n","35369  108 St . Georges Terrace , with 50 floors , is...  \n","\n","[35370 rows x 2 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["train_df"]},{"cell_type":"markdown","metadata":{"id":"BmNCNLvBNy2l"},"source":["Visualizamos brevemente el conjunto de datos y exploramos alguno de los ejemplos con la finalidad de comprender los datos que utilizaremos durante el entrenamiento y la evaluación del modelo."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":420,"status":"ok","timestamp":1653813131308,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"0FqMV84uFpKb","outputId":"e6834ab5-4fb1-45e9-dbfd-27db145d75e9"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-32b7de3f-b31e-4be3-9859-e817b9e9ba05\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input_text</th>\n","      <th>target_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Acharya Institute of Technology | city | Banga...</td>\n","      <td>The Acharya Institute of Technology in Karnata...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11th Mississippi Infantry Monument | country |...</td>\n","      <td>The 11th Mississippi Infantry monument is loca...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A-Rosa Luna | ship displacement | 1850.0 (tonn...</td>\n","      <td>The A-Rosa Luna was ordered on 22 January 2004...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>United Kingdom | leader | Elizabeth II</td>\n","      <td>Elizabeth II is the head of state in the Unite...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AIDAluna | owner | AIDA Cruises &amp;&amp; AIDAluna | ...</td>\n","      <td>AIDA Cruises own the AIDAluna which was built ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32b7de3f-b31e-4be3-9859-e817b9e9ba05')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-32b7de3f-b31e-4be3-9859-e817b9e9ba05 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-32b7de3f-b31e-4be3-9859-e817b9e9ba05');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                          input_text  \\\n","0  Acharya Institute of Technology | city | Banga...   \n","1  11th Mississippi Infantry Monument | country |...   \n","2  A-Rosa Luna | ship displacement | 1850.0 (tonn...   \n","3             United Kingdom | leader | Elizabeth II   \n","4  AIDAluna | owner | AIDA Cruises && AIDAluna | ...   \n","\n","                                         target_text  \n","0  The Acharya Institute of Technology in Karnata...  \n","1  The 11th Mississippi Infantry monument is loca...  \n","2  The A-Rosa Luna was ordered on 22 January 2004...  \n","3  Elizabeth II is the head of state in the Unite...  \n","4  AIDA Cruises own the AIDAluna which was built ...  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1653813132072,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"UkbUeHCYsJem","outputId":"1b7c737d-386d-4e87-e8c2-5fb74e0f3c70"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-9358f3e8-a6e2-438f-9178-1120b9556881\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input_text</th>\n","      <th>target_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Super Capers | editing | Stacy Katzman &amp;&amp; Supe...</td>\n","      <td>['Both Michael Rooker and Tom Sizemore starred...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Expect a Miracle | runtime | 54.56 &amp;&amp; Expect a...</td>\n","      <td>['Expect a Miracle in the instrumental music g...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Olga Bondareva | birth date | 1937-04-27</td>\n","      <td>['Olga Bondareva was born on April 27 , 1937 ....</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Darinka Dentcheva | known for | Stochastic pro...</td>\n","      <td>['Darinka Dentcheva is known for her work with...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>The Fellowship of the Ring | followed by | The...</td>\n","      <td>[ The Fellowship of the Ring was written by J ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9358f3e8-a6e2-438f-9178-1120b9556881')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9358f3e8-a6e2-438f-9178-1120b9556881 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9358f3e8-a6e2-438f-9178-1120b9556881');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                          input_text  \\\n","0  Super Capers | editing | Stacy Katzman && Supe...   \n","1  Expect a Miracle | runtime | 54.56 && Expect a...   \n","2           Olga Bondareva | birth date | 1937-04-27   \n","3  Darinka Dentcheva | known for | Stochastic pro...   \n","4  The Fellowship of the Ring | followed by | The...   \n","\n","                                         target_text  \n","0  ['Both Michael Rooker and Tom Sizemore starred...  \n","1  ['Expect a Miracle in the instrumental music g...  \n","2  ['Olga Bondareva was born on April 27 , 1937 ....  \n","3  ['Darinka Dentcheva is known for her work with...  \n","4  [ The Fellowship of the Ring was written by J ...  "]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["test_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1653813132504,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"WkkjD1g8sKs-","outputId":"7c80a08d-b126-4ca3-a5fa-3f1f3827ba74"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-9f9abd62-e448-4043-b2b0-5863286bdfa3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input_text</th>\n","      <th>target_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Trane | product | Building Management System &amp;...</td>\n","      <td>['The Trane company is a subsidiary and it man...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Walter Baade | doctoral student | Allan Sandage</td>\n","      <td>['Allan Sandage was a doctoral student of Walt...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Tarrant County, Texas | county seat | Fort Wor...</td>\n","      <td>['Arlington is part of the state of Texas , wh...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Amatriciana sauce | region | Lazio &amp;&amp; Amatrici...</td>\n","      <td>['Pecorino Romano is an ingredient of Amatrici...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Ahmad Kadhim Assad | club | Esteghlal Ahvaz F....</td>\n","      <td>[ Ahmad Kadhim Assad's club is Esteghlal Ahvaz...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f9abd62-e448-4043-b2b0-5863286bdfa3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9f9abd62-e448-4043-b2b0-5863286bdfa3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9f9abd62-e448-4043-b2b0-5863286bdfa3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                          input_text  \\\n","0  Trane | product | Building Management System &...   \n","1    Walter Baade | doctoral student | Allan Sandage   \n","2  Tarrant County, Texas | county seat | Fort Wor...   \n","3  Amatriciana sauce | region | Lazio && Amatrici...   \n","4  Ahmad Kadhim Assad | club | Esteghlal Ahvaz F....   \n","\n","                                         target_text  \n","0  ['The Trane company is a subsidiary and it man...  \n","1  ['Allan Sandage was a doctoral student of Walt...  \n","2  ['Arlington is part of the state of Texas , wh...  \n","3  ['Pecorino Romano is an ingredient of Amatrici...  \n","4  [ Ahmad Kadhim Assad's club is Esteghlal Ahvaz...  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["test_train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1653813133305,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"NeXmb48GT5Tk","outputId":"6bcbf7ef-eaef-4c35-92a6-95108494ccd9"},"outputs":[{"data":{"text/plain":["35370"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["len(train_df)"]},{"cell_type":"markdown","metadata":{"id":"wHGqZM0-c5Ud"},"source":["## Tokenización de los datos\n","\n","\n","En este apartado, tokenizamos los datos de entrada ya que haciendo uso del T5Tokenizer de la biblioteca Transformers. Este tokenizador es propio del modelo T5 y hace uso de SentencePiece para la codificación y decodificación de los datos.\n","\n","\n","A continuación, cargamos el tokenizador."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oyExGtIJO86I"},"outputs":[],"source":["tokenizer = T5Tokenizer.from_pretrained('t5-base')"]},{"cell_type":"markdown","metadata":{"id":"tSc2hz7KObGO"},"source":["Visualizamos el primer ejemplo del conjunto de datos con la finalidad de recordar como está compuesto."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1653813144498,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"3IjF-x1kiqUq","outputId":"59eca55d-69af-41c8-cece-264e76cac987"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Acharya Institute of Technology | city | Bangalore && Acharya Institute of Technology | established | 2000 && Acharya Institute of Technology | country |  India  && Acharya Institute of Technology | state | Karnataka && Acharya Institute of Technology | affiliation | Visvesvaraya Technological University'"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["input_batch = train_df['input_text'][0]\n","input_batch"]},{"cell_type":"markdown","metadata":{"id":"abqImwwHuJ__"},"source":["A continuación, codifico este primer ejemplo del conjunto. Pruebo con  un max_length = 3 para comprobar el truncamiento correcto de datos."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1653813144499,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"sNFLckInPCxP","outputId":"cac77086-ff1c-4d61-8b46-535ff26a303d"},"outputs":[{"data":{"text/plain":["tensor([[14217,  1208,     1]])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["encoded = tokenizer.encode(input_batch, max_length=3,return_tensors='pt',truncation=True, add_special_tokens=True)\n","encoded"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1653813144500,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"1iZjMCYaoLr6","outputId":"34e92009-89fc-46b8-9d90-4a338bce0c0e"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Achary</s>'"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(encoded[0])"]},{"cell_type":"markdown","metadata":{"id":"zk1Y_Jv4uNh6"},"source":["En la prueba anterior podemos ver como únicamente ha tokenizado los primeros tres tokens del ejemplo.\n","\n","A continuación, establecemos un límite de tokenización mucho mayor con la finalidad de que no corte la secuencia de entrada."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1653813144501,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"-XGEJOh_ikgR","outputId":"da098c9a-f7bd-4d87-80ff-f7ab5c3f0ca4"},"outputs":[{"data":{"text/plain":["tensor([[14217,  1208,     9,  2548,    13,  3669,  1820,   690,  1820, 23689,\n","             3,   184,   184, 14217,  1208,     9,  2548,    13,  3669,  1820,\n","          2127,  1820,  2766,     3,   184,   184, 14217,  1208,     9,  2548,\n","            13,  3669,  1820,   684,  1820,  1547,     3,   184,   184, 14217,\n","          1208,     9,  2548,    13,  3669,  1820,   538,  1820,  4556,    29,\n","           144,  5667,     3,   184,   184, 14217,  1208,     9,  2548,    13,\n","          3669,  1820, 24405,  1820, 13291,   162,     7,   900,  2866,     9,\n","         25789,  6207,   636,     1]])"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["input_batch = train_df['input_text'][0]\n","encoded = tokenizer.encode(input_batch, max_length=1024,return_tensors='pt',truncation=True)\n","encoded"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1653813145717,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"ltlM5J2mYWqd","outputId":"56a38137-3897-4acc-bf89-f758be7fa0a9"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Acharya Institute of Technology | city | Bangalore && Acharya Institute of Technology | established | 2000 && Acharya Institute of Technology | country | India && Acharya Institute of Technology | state | Karnataka && Acharya Institute of Technology | affiliation | Visvesvaraya Technological University</s>'"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(encoded[0])"]},{"cell_type":"markdown","metadata":{"id":"NYW6LP6XO3DM"},"source":["Como se comprueba anateriormente, el proceso de tokenización se compone de dos procesos inversos: codificación y decodificación. \n","\n","Tras la aplicación de ambos procesos de manera seguida se obtienen la misma secuencia de entrada por lo que el proceso de tokenización se realizó de manera correcta."]},{"cell_type":"markdown","metadata":{"id":"2PPEQ8OHc3gu"},"source":["### Distribución de tokens\n","\n","Es importante conocer el límite que podemos establecer al proceso de tokenización de los datos ya que durante el entrenamiento o ajuste deberán ser introducidos en lotes y cada uno de los ejemplos del lote deben tener la misma longitud sin truncamiento.\n","\n","A continuación se realiza un estudio del número máximo de tokens del conjunto de datos, tanto de manera separada respecto a los datos de entrada y de destino, como conjunta."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0b3SWpyLfB-K"},"outputs":[],"source":["train_df_encoded = []\n","for _, example in train_df.iterrows():\n","  input_text = example['input_text']\n","  input_encoded = tokenizer.encode(input_text, padding=True, max_length=1024, return_tensors='pt', truncation=True)\n","\n","  target_text = example['target_text']\n","  target_encoded = tokenizer.encode(target_text, padding=True, max_length=1024, return_tensors='pt', truncation=True)\n","\n","  train_df_encoded.append((input_encoded,target_encoded))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1653813177198,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"Cqc2J4HXe1dp","outputId":"d9ae4e0d-1882-434a-a3bc-3793647c6cad"},"outputs":[{"data":{"text/plain":["(tensor([[14217,  1208,     9,  2548,    13,  3669,  1820,   690,  1820, 23689,\n","              3,   184,   184, 14217,  1208,     9,  2548,    13,  3669,  1820,\n","           2127,  1820,  2766,     3,   184,   184, 14217,  1208,     9,  2548,\n","             13,  3669,  1820,   684,  1820,  1547,     3,   184,   184, 14217,\n","           1208,     9,  2548,    13,  3669,  1820,   538,  1820,  4556,    29,\n","            144,  5667,     3,   184,   184, 14217,  1208,     9,  2548,    13,\n","           3669,  1820, 24405,  1820, 13291,   162,     7,   900,  2866,     9,\n","          25789,  6207,   636,     1]]),\n"," tensor([[   37, 14217,  1208,     9,  2548,    13,  3669,    16,  4556,    29,\n","            144,  5667,     3,     6, 23689,     3,     6,  1547,    47,  2127,\n","             16,  2766,     3,     5,    94,    19, 18273,    12,     8, 13291,\n","            162,     7,   900,  2866,     9, 25789,  6207,   636,     3,     5,\n","              1]]))"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["train_df_encoded[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h0ocm4Iqct0J"},"outputs":[],"source":["lengths_inputs = []\n","lengths_target = []\n","\n","for example in train_df_encoded:\n","  input_tokens = tokenizer.convert_ids_to_tokens(example[0][0])\n","  lengths_inputs.append(len(input_tokens))\n","\n","  target_tokens = tokenizer.convert_ids_to_tokens(example[1][0])\n","  lengths_target.append(len(target_tokens))\n"]},{"cell_type":"markdown","metadata":{"id":"RKehgdERPkhl"},"source":["Para visualizar la distribución de longitudes construimos unas gráficas que nos ayuden a realizar esta tarea."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BrvjH0iyicxp"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from statistics import mean, stdev, variance\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QX6Lbl93rd1d"},"outputs":[],"source":["def showLenDistribution(all_lengths,max_linspace,steps):\n","\n","  plt.hist(all_lengths, np.linspace(0, max_linspace, steps))\n","  plt.ylim(plt.ylim())\n","  max_length = max(all_lengths)\n","  plt.plot([max_length, max_length], plt.ylim())\n","  plt.title(f'Máximo número de tokens en un ejemplo: {max_length}');\n","  plt.show()\n","\n","  print(f'          Media: {mean(all_lengths)}')\n","  print(f'          Desviación: {stdev(all_lengths)}')\n","  print(f'          Varianza: {variance(all_lengths)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1653813204185,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"Ifs3kGY4rkw_","outputId":"707c9c38-b15d-456b-ff75-4b53046052e1"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["          Media: 44.33454905286966\n","          Desviación: 25.585019822295024\n","          Varianza: 654.5932393072293\n"]}],"source":["showLenDistribution(lengths_inputs, 200, 50)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336},"executionInfo":{"elapsed":583,"status":"ok","timestamp":1653813209148,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"NzOMaAwerpDU","outputId":"ae1fe1af-eb72-471a-fb5b-7efbf4817c0b"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["          Media: 34.794515125812836\n","          Desviación: 16.824764661862773\n","          Varianza: 283.0727059270663\n"]}],"source":["showLenDistribution(lengths_target, 200, 50)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336},"executionInfo":{"elapsed":1564,"status":"ok","timestamp":1653813210703,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"4j9BgiKax04-","outputId":"ebaff81f-8169-4ad7-bb41-e3e748cd5e07"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["          Media: 39.56453208934125\n","          Desviación: 22.1715973365171\n","          Varianza: 491.5797284526521\n"]}],"source":["showLenDistribution([*lengths_inputs, *lengths_target], 200, 50)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8G91l5FsjQcJ"},"outputs":[],"source":[" # Establecemos el máximo número de tokens a un número ligeramente mayor al dado\n","MAX_TOKENS = 256"]},{"cell_type":"markdown","metadata":{"id":"UH4eXl_0YhIp"},"source":["## Definicion del tokenizer y el modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":340,"status":"ok","timestamp":1653837851850,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"elJUtLBJYcYa","outputId":"2bc45198-aac6-4c30-ca9e-a671c17383fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running on the CPU\n"]}],"source":["if torch.cuda.is_available():\n","    dev = torch.device(\"cuda:0\") \n","    print(\"Running on the GPU\")\n","else:\n","    dev = torch.device(\"cpu\")\n","    print(\"Running on the CPU\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":49478,"status":"ok","timestamp":1653837901327,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"e0ffBIBEYjlp","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["c4400c0814ff45fa93768fefa5f0050f","9773a33679c3421182825e469ab46dff","f97b84d394784067b110e89aaf25fa22","3ed8b3949bb940a6a4994e5b717f5f30","2ba3e6d3aa19456db75abb6b17c2532a","3e36f8e17ab342898c367248e6c202e6","b4b92fe0866841cdaf7ae5a30b565b08","56cf4b248f9c4c16880600a463a6d4d6","2412b4fe120d4af8a3ba8837db18dfac","eb62f4d0329a42fca113a58e039d21f0","8bf87df7ec6f44ffba43454ac1a354a4","8cc660ae2b62436db2f91722286dd713","47863175f19c47f8ab4852d923d1dde7","324cad3787e2488aa3843c63f986f082","e637b44187f743bfbb93a08e7f17ea7f","5b816b5c1bc04bd9984893a377a64470","16f92bbfeddc4d45902fecae8d26467e","5c812489bccf427e8de08ef368594b3f","44cfc2c2a1c645b98af5a51a315ec237","89c1fcd926024b11a831b759c1d8f063","a82a948b584c4c588ae5abad8aaaeee1","8e0dce6bd31c48fcb30bd993f9a2ba5c","7ac8c90fa3ec4dd983c5e0724754c8a5","0f655c71aa524d328e83a7c0c8892af6","7ee3776a658342f2be619c8b4acc4d2b","08de41e27c734a7ab6c9fb2f32ceb8fa","1c5214c0b1a947148f3b6e6ce21e6977","bf8070cafa06409e8fb7fbcdaeffbaff","536da5a33f7f4fb9a572d5bcd4be1c7d","652c0dd7ebe74cc0a17394fc62eccc62","23852c2717f543d898872943e946d40a","79e25a4c2fb24ddd873fa4c0b385533e","9dac17bd291046d88f4e18f56a236154"]},"outputId":"8291e340-83b7-4e06-f00e-d74d62ac5fe3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4400c0814ff45fa93768fefa5f0050f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cc660ae2b62436db2f91722286dd713"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/850M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ac8c90fa3ec4dd983c5e0724754c8a5"}},"metadata":{}}],"source":["tokenizer = T5Tokenizer.from_pretrained('t5-base')\n","model = T5ForConditionalGeneration.from_pretrained('t5-base', return_dict=True)\n","model = model.to(dev)"]},{"cell_type":"markdown","metadata":{"id":"JXMG_JTFQWZF"},"source":["## Definición de hiperparámetros"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zGfaigiqnZW5"},"outputs":[],"source":["batch_size=8\n","num_of_batches=len(train_df)/batch_size\n","num_of_epochs=1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SQDfdl3mxYf_"},"outputs":[],"source":["num_of_batches=int(num_of_batches)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vntB9XBaYdJD"},"outputs":[],"source":["optimizer = Adafactor(model.parameters(),lr=1e-3,\n","                      eps=(1e-30, 1e-3),\n","                      clip_threshold=1.0,\n","                      decay_rate=-0.8,\n","                      beta1=None,\n","                      weight_decay=0.0,\n","                      relative_step=False,\n","                      scale_parameter=False,\n","                      warmup_init=False)"]},{"cell_type":"markdown","metadata":{"id":"3spIRKg3BhRD"},"source":["## Creación del conjunto de datos para el entrenamiento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9hei-P4J16xx"},"outputs":[],"source":["from torch.utils.data import Dataset\n","from IPython.display import HTML, display\n","import ast\n","\n","class WebNLG(Dataset):\n","  def __init__(self, dataset_df, tokenizer, bos_token, label_split):\n","    self.dataset_df = dataset_df\n","    self.tokenizer = tokenizer\n","    self.bos_token = bos_token    \n","    self.inputbatch = {'input_ids': [],'attention_mask':[]}\n","    self.targetbatch = {'input_ids': [],'attention_mask':[]}\n","    self.targetdecoded = []\n","    self.label_split = label_split\n","  \n","  def __len__(self):\n","    return len(self.dataset_df)\n","  \n","  def __getitem__(self, index):\n","\n","    if isinstance(index, slice):\n","      input_ids   = self.inputbatch[\"input_ids\"][index.start:index.stop]\n","      target_ids  = self.targetbatch[\"input_ids\"][index.start:index.stop]\n","\n","      if(self.label_split==\"test\"):\n","        return  {\"input_ids\": input_ids,  \"target_ids\": target_ids,\"target_decode\": self.targetdecoded[index.start:index.stop]}\n","      return {\"input_ids\": input_ids,  \"target_ids\": target_ids}\n","\n","    elif isinstance(index, int):\n","      input_ids   = self.inputbatch[\"input_ids\"][index]\n","      target_ids  = self.targetbatch[\"input_ids\"][index]\n","\n","      if(self.label_split==\"test\"):\n","        return  {\"input_ids\": input_ids,  \"target_ids\": target_ids,\"target_decode\": self.targetdecoded[index]}\n","      else:\n","        return  {\"input_ids\": input_ids,  \"target_ids\": target_ids}\n","\n","\n","\n","  def build(self, num_of_batches, batch_size):\n","\n","    out = display(self._progress(1, num_of_batches+1), display_id=True)\n","    \n","\n","    for i in range(num_of_batches):\n","      inputbatch_aux=[]\n","      targetbatch_aux=[]\n","      if(self.label_split==\"test\"):self.targetdecoded.append([])\n","      subset_df = self.dataset_df[i*batch_size:i*batch_size+batch_size]\n","\n","      for indx, row in subset_df.iterrows():\n","        input = self.bos_token + \" \" + row['input_text'] + \"</s>\"\n","        target = row['target_text'] + \"</s>\"\n","        inputbatch_aux.append(input)\n","        targetbatch_aux.append(target)\n","\n","      # tokenize inputs\n","      tokenized_inputs = self.tokenizer.batch_encode_plus(\n","          inputbatch_aux, padding=True, max_length = MAX_TOKENS, return_tensors='pt')\n","\n","      # tokenize target\n","      if(self.label_split==\"test\"):\n","        tokenized_targets= {'input_ids':[]}\n","        for t in targetbatch_aux:\n","          t = ast.literal_eval(t[:-4])\n","          if(self.label_split==\"test\"):self.targetdecoded[-1].append([])\n","          for indx in range(len(t)):    \n","            if(self.label_split==\"test\"):\n","              t[indx] = t[indx] + \" </s>\"\n","              self.targetdecoded[-1][-1].append(t[indx])\n","            else:\n","              t[indx] = t[indx] + \"</s>\"\n","          tokenized_targets['input_ids'].append(self.tokenizer.batch_encode_plus(\n","              t,padding=True, max_length = MAX_TOKENS, return_tensors='pt')['input_ids'])\n","\n","      else:\n","        tokenized_targets = self.tokenizer.batch_encode_plus(\n","              targetbatch_aux, padding=True, max_length = MAX_TOKENS, return_tensors='pt')\n","\n","      self.inputbatch['input_ids'].append(tokenized_inputs['input_ids'])\n","      self.targetbatch['input_ids'].append(tokenized_targets['input_ids'])\n","\n","      out.update(self._progress(i+1,num_of_batches+1))\n","\n","\n","  def _progress(self, value, max=100):\n","      return HTML(\"\"\" \n","          <progress\n","              value='{value}'\n","              max='{max}',\n","              style='width: 100%'\n","          >\n","              {value}\n","          </progress>\n","      \"\"\".format(value=value, max=max))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":9322,"status":"ok","timestamp":1653321463001,"user":{"displayName":"María Cristina Alameda Salas","userId":"10770841571665636441"},"user_tz":-120},"id":"B-llTC4G5pj5","outputId":"cbcb4ad4-52c3-46bc-fbac-a7a897ac57af"},"outputs":[{"data":{"text/html":[" \n","          <progress\n","              value='1087'\n","              max='1088',\n","              style='width: 100%'\n","          >\n","              1087\n","          </progress>\n","      "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["train_dataset = WebNLG(train_df, tokenizer,'WebNLG:', 'train')\n","train_dataset.build(num_of_batches, batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":406,"status":"ok","timestamp":1653321463403,"user":{"displayName":"María Cristina Alameda Salas","userId":"10770841571665636441"},"user_tz":-120},"id":"iWsl_bf5a_tm","outputId":"a5a87040-fc4f-4d9c-99bf-ee2873c47a6d"},"outputs":[{"data":{"text/html":[" \n","          <progress\n","              value='12'\n","              max='13',\n","              style='width: 100%'\n","          >\n","              12\n","          </progress>\n","      "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["test_dataset = WebNLG(test_df[:100], tokenizer,'WebNLG:', 'test')\n","test_dataset.build(int(100/batch_size), batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1653321463403,"user":{"displayName":"María Cristina Alameda Salas","userId":"10770841571665636441"},"user_tz":-120},"id":"AJOmpccf7lco","outputId":"affc4e41-f022-4a0f-cbff-c1dc5fc65942"},"outputs":[{"data":{"text/html":[" \n","          <progress\n","              value='12'\n","              max='13',\n","              style='width: 100%'\n","          >\n","              12\n","          </progress>\n","      "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["testtrain_dataset = WebNLG(test_train_df[:100], tokenizer,'WebNLG:', 'test')\n","testtrain_dataset.build(int(100/batch_size), batch_size)"]},{"cell_type":"markdown","metadata":{"id":"hMe1hKshLgJn"},"source":["## Ajuste del modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4LRKbnt7ZNQq"},"outputs":[],"source":["def progress(loss,value, max=100):\n","    return HTML(\"\"\" Batch loss :{loss}\n","        <progress\n","            value='{value}'\n","            max='{max}',\n","            style='width: 100%'\n","        >\n","            {value}\n","        </progress>\n","    \"\"\".format(loss=loss,value=value, max=max))"]},{"cell_type":"markdown","metadata":{"id":"CKNomuhWLfQo"},"source":["Para la evaluación"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_moPQBx8mywQ"},"outputs":[],"source":["from nltk.translate.bleu_score import sentence_bleu"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F1asNMTKclLI"},"outputs":[],"source":["def validate(dataset):\n","\n","  bleu = []\n","  loss = []\n","\n","  for batch in dataset:\n","    one_labels = []\n","\n","\n","    for l in batch['target_ids']:\n","      one_labels.append(list(l[0].numpy()))\n","\n","    maxlen = max(len(i) for i in one_labels)\n","\n","    for row in one_labels:\n","      if len(row) < maxlen:\n","          for k in range((maxlen - len(row))):\n","            row.extend([0])\n","\n","    one_labels = torch.tensor(one_labels)\n","  \n","    # Calculo loss\n","    output = model(input_ids=batch['input_ids'].to(dev), labels = one_labels.to(dev))\n","    loss.append(output.loss.item())\n","\n","\n","    targets = model.generate(input_ids=batch['input_ids'].to(dev), num_beams=2, no_repeat_ngram_size=2)\n","\n","\n","    for label, target in zip(batch['target_decode'], targets):\n","      target = target.cpu().numpy()\n","      target = target[target != (1 and 0)]\n","\n","\n","      label_decoded =  [t.split() for t in label] \n","      target_decoded = tokenizer.decode(target)   \n","      target_decoded =  target_decoded.replace('</s>',' </s>')\n","      target_decoded =  target_decoded.replace('.',' .')\n","      target_decoded =  target_decoded.replace(',',' ,')\n","      target_decoded =  target_decoded.replace('(','( ')\n","      target_decoded =  target_decoded.replace(')',' )')\n","      \n","      #calculare bleu score\n","      #print(f'label_decoded: {label_decoded}')\n","      #print(f'target_decoded: {target_decoded.split()}')\n","      bleu_score = sentence_bleu(label_decoded,target_decoded.split(),weights=(0.35, 0.3, 0.2, 0.15))\n","      #print(f'bleu: {bleu_score}')\n","      bleu.append(bleu_score)\n","      \n","  return bleu, loss"]},{"cell_type":"markdown","metadata":{"id":"RpBMHgkkLkbJ"},"source":["Para entrenar"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"executionInfo":{"elapsed":473629,"status":"ok","timestamp":1653321938550,"user":{"displayName":"María Cristina Alameda Salas","userId":"10770841571665636441"},"user_tz":-120},"id":"qTvda_lWx2nC","outputId":"8da3668b-70af-41fe-c7fc-25f9aaa2573c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Running epoch: 1\n"]},{"data":{"text/html":[" Batch loss :0.3491833806037903\n","        <progress\n","            value='1086'\n","            max='1088',\n","            style='width: 100%'\n","        >\n","            1086\n","        </progress>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Bleu media de val: 0.0908222744991861\n","Bleu media de train: 0.1613274286569327\n","Loss media de val: 9.996417244275412\n","Loss media de train: 10.143216331799826\n","____________________________________\n","Bleu media de val: 0.317722170943374\n","Bleu media de train: 0.3279374398894605\n","Loss media de val: 0.7532945473988851\n","Loss media de train: 0.6385251606504122\n","____________________________________\n","Bleu media de val: 0.30760913612739643\n","Bleu media de train: 0.32146025997197897\n","Loss media de val: 0.7894082317749659\n","Loss media de train: 0.6859502196311951\n","____________________________________\n","Epoch: 1 , Running loss: 0.6063692831154142\n"]}],"source":["loss_per_steps_total = []\n","losstrain_per_steps = []\n","lossval_per_steps = []\n","bleuval_per_steps = []\n","bleutrain_per_steps = [] \n","\n","model.train()\n","\n","for epoch in range(1,num_of_epochs+1):\n","  print('Running epoch: {}'.format(epoch))\n","  \n","  running_loss=0\n","\n","  out = display(progress(1, num_of_batches+1), display_id=True)\n","\n","  for i in range(num_of_batches):\n","\n","    subset = train_dataset[i]\n","\n","    inputbatch = subset['input_ids'].to(dev)\n","    labelbatch = subset['target_ids'].to(dev)\n","\n","    # clear out the gradients of all Variables \n","    optimizer.zero_grad()\n","\n","    # Forward propogation\n","    outputs = model(input_ids=inputbatch, labels=labelbatch)\n","\n","    loss = outputs.loss\n","    loss_num=loss.item()\n","    logits = outputs.logits\n","    running_loss+=loss_num\n","\n","    if i%100 ==0:      \n","      loss_per_steps_total.append(loss_num)\n","    out.update(progress(loss_num,i, num_of_batches+1))\n","\n","    if i % 500 ==0:\n","\n","      \n","      model.eval()\n","\n","\n","      bleuval, lossval = validate(test_dataset)\n","      bleutrain, losstrain = validate(testtrain_dataset)\n","\n","      \n","      bleuval_per_steps.append(sum(bleuval)/len(bleuval))\n","      print(f\"Bleu media de val: {bleuval_per_steps[-1]}\")\n","      bleutrain_per_steps.append(sum(bleutrain)/len(bleutrain))\n","      print(f\"Bleu media de train: {bleutrain_per_steps[-1]}\")\n","\n","      lossval_per_steps.append(sum(lossval)/len(lossval))\n","      print(f\"Loss media de val: {lossval_per_steps[-1]}\")\n","      losstrain_per_steps.append(sum(losstrain)/len(losstrain))\n","      print(f\"Loss media de train: {losstrain_per_steps[-1]}\")\n","      print(\"____________________________________\")\n","      \n","      model.train()\n","\n","    # calculating the gradients\n","    loss.backward()\n","\n","    #updating the params\n","    optimizer.step()\n","\n","  running_loss=running_loss/int(num_of_batches)\n","  print('Epoch: {} , Running loss: {}'.format(epoch, running_loss))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D3GIhkmRV8ss"},"outputs":[],"source":["import pickle\n","\n","with open('/content/drive/MyDrive/TFG/Sistema final/Modelos/Loss_model_10000.ob', 'wb') as fp:\n","    pickle.dump(loss_per_steps_total, fp)\n","\n","with open('/content/drive/MyDrive/TFG/Sistema final/Modelos/Bleu_train_10000.ob', 'wb') as fp:\n","    pickle.dump(bleutrain_per_steps, fp)\n","\n","with open('/content/drive/MyDrive/TFG/Sistema final/Modelos/Bleu_val_10000.ob', 'wb') as fp:\n","    pickle.dump(bleuval_per_steps, fp)\n","\n","with open('/content/drive/MyDrive/TFG/Sistema final/Modelos/Loss_train_10000.ob', 'wb') as fp:\n","    pickle.dump(losstrain_per_steps, fp)\n","\n","with open('/content/drive/MyDrive/TFG/Sistema final/Modelos/Loss_val_10000.ob', 'wb') as fp:\n","    pickle.dump(lossval_per_steps, fp)"]},{"cell_type":"markdown","metadata":{"id":"Nv3VHD585lc9"},"source":["## Testing the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cbBW7ZcWbYSf"},"outputs":[],"source":["model.save_pretrained(\"Modelo T5 Final/Modelos/webnlg/t5/t5_3epoch_30000examples\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":91},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1653813762621,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"JD6M4tb8l2Vs","outputId":"d2292816-3d06-469a-b994-7d3eb132ab0a"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[  101,    29, 18207,   517,    10,   108,    26,  3272,   189,  1820,\n","         22295,  1820, 10619,     3,   184,   184,   108,    26,  3272,   189,\n","          1820,   577,  1820,  3370,     1]], device='cuda:0')\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'<pad> Sidharth, a football player, is from the city of Delhi'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["model.eval()\n","input_ids = tokenizer.encode(\"WenNLG: sidharth | hometown | Delhi && sidharth | play |  football </s>\", return_tensors=\"pt\")  # Batch size 1\n","input_ids=input_ids.to(dev)\n","print(input_ids)\n","outputs = model.generate(input_ids)\n","tokenizer.decode(outputs[0])"]},{"cell_type":"markdown","metadata":{"id":"S_bvCAL5gzFh"},"source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","# Prueba"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4103,"status":"ok","timestamp":1653823440169,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"KWFhQMH2bf1I","outputId":"fc3528c1-cd23-44e2-8eef-10f2bf422ebd"},"outputs":[{"data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(32128, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",")"]},"execution_count":200,"metadata":{},"output_type":"execute_result"}],"source":["model = model.from_pretrained(\"Modelo T5 Final/Modelos/webnlg/t5/t5_1epoch_30000examples\")\n","model.to(dev)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1653817792172,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"IbbkVA9J1Ui7","outputId":"3c383ed6-3c0e-422c-bb9f-decfb46e58bf"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'<pad> Mary was born on 03/05/1950 in London.</s>'"]},"execution_count":124,"metadata":{},"output_type":"execute_result"}],"source":["model.eval()\n","input_ids = tokenizer.encode(\"WebNLG: Mary | hometown | London && Mary | birthDate | 03-05-1950 </s>\", return_tensors=\"pt\")  # Batch size 1\n","input_ids=input_ids.to(dev)\n","outputs = model.generate(input_ids)\n","result = tokenizer.decode(outputs[0])\n","result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":656,"status":"ok","timestamp":1653817792818,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"K9SCUFEp1Ui8","outputId":"3eaa159a-7a99-47bc-c8ec-bc5fefaac037"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'<pad> David first played for FC Bayern_Munich in 2005 and is a football player.</s>'"]},"execution_count":125,"metadata":{},"output_type":"execute_result"}],"source":["model.eval()\n","input_ids = tokenizer.encode(\"WebNLG: David | occupation | football_player && David | first_club |FC_Bayern_Munich && David | started_playing | 2005 </s>\", return_tensors=\"pt\")  # Batch size 1\n","input_ids=input_ids.to(dev)\n","outputs = model.generate(input_ids, max_length=100)\n","result = tokenizer.decode(outputs[0])\n","result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1653817792819,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"INksfM-E1Ui8","outputId":"7e799c32-cee2-4160-e032-440aaebd0e9a"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'<pad> Mario is a performer of the bodybuilding, he is a performer of exercise and won the title of the champion of the bodybuilding, awards.</s>'"]},"execution_count":126,"metadata":{},"output_type":"execute_result"}],"source":["model.eval()\n","input_ids = tokenizer.encode(\"WebNLG: Mario | hobby | exercise && Mario | win | bodybuilding_awards</s>\", return_tensors=\"pt\")  # Batch size 1\n","input_ids=input_ids.to(dev)\n","outputs = model.generate(input_ids,max_length=100)\n","result = tokenizer.decode(outputs[0])\n","result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u3z3KLUPj30L"},"outputs":[],"source":["def to_sentence(sentence,model):\n","  model.eval()\n","  sentence2 = \"WebNLG: \" +sentence + \" </s>\"\n","  input_ids = tokenizer.encode(sentence2, return_tensors=\"pt\")  # Batch size 1\n","  input_ids=input_ids.to(dev)\n","  outputs = model.generate(input_ids, num_beams=5, temperature=1.5, max_length=100)\n","  return tokenizer.decode(outputs[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":636,"status":"ok","timestamp":1653817793448,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"8zbEh3ii9of8","outputId":"60820be1-51b8-4089-d920-32df7b0c7b09"},"outputs":[{"name":"stdout","output_type":"stream","text":["<pad> Mary was born on the 15th February, 1950 in London, England. She worked as a teacher.</s>\n"]}],"source":["sentence = 'Mary | hometown | London, England && Mary | birthdate | 15-02-1950 && Mary | occupation | teacher'\n","\n","result1 = to_sentence(sentence,model)\n","\n","print(result1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":649,"status":"ok","timestamp":1653817794093,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"A3QxACgBKyd4","outputId":"1737fa0c-4595-4f02-d8a5-6965d1d09606"},"outputs":[{"name":"stdout","output_type":"stream","text":["['<pad> Juan, who served as a labrador, was alcoholic.</s>', \"<pad> The uncle of Mary's uncle is Olivia.</s>\", \"<pad> Mary's siblings are 14.</s>\"]\n"]}],"source":["data = []\n","data.append(\"Juan | occupation | labrador && Juan | was | alcoholic\")\n","data.append(\"Mary | uncle | Olivia\")\n","data.append(\"Mary | siblings | 14\")\n","\n","result = []\n","for sentence in data:\n","  text_en = to_sentence(sentence,model)\n","  result.append(text_en)\n","print(result)"]},{"cell_type":"markdown","metadata":{"id":"3lp6uJxVSL2t"},"source":["## Historia de vida completa"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b3Glk6GZSwot"},"outputs":[],"source":["def to_sentence(sentence,model,**args):\n","  model.eval()\n","  sentence2 = \"WebNLG:\" +sentence + \"</s>\"\n","  input_ids = tokenizer.encode(sentence2, return_tensors=\"pt\")  # Batch size 1\n","  input_ids=input_ids.to(dev)\n","  outputs = model.generate(input_ids,**args)\n","  return tokenizer.decode(outputs[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sSZmklXxSNPt"},"outputs":[],"source":["s00 = \"Elisa | birth place | Lugo, Galicia && Elisa | birth date | 18-05-1937 && Elisa | age | 82 && Elisa | father’s name | Juan && Elisa | mother’s name | Eva\"\n","s0 = \"Juan | occupation | labrador && Juan | wife | Eva && Juan | birth place | Santander && Juan | birth date | 25-11-1911 && Eva | birth place | Barcelona && Eva | birth date | 12-01-1912 && Eva | occupation | seamstress\"\n","s1 = \"Juan | occupation | labrador && Juan | wife | Eva && Juan | birth place | Santander && Juan | birth date | 25-11-1911 && Eva | birth place | Barcelona && Eva | birth date | 12-01-1912 && Eva | occupation | seamstress\"\n","s2 = \"Elisa | educated at | La Salle's school && La Salle's school | was | all-girl catholic && Elisa | favorite school subjects | history && Elisa | favorite school subjects | drawing \"\n","s3 = \"Elisa | best friend | Veronica && Elisa | best friend | Luis && Elisa | played with | friends && Elisa | favorite games | hide-and-seek && Elisa | go swimming with | friends \"\n","s4 = \"Elisa'father | died | when Elisa was 13 years old && Elisa | help her mother | with housework \"\n","s5 = \"Elisa | drop out of school | when Elisa was 15 years old && Elisa | drop out of school | because of poverty \"\n","s6 = \"Elisa | worked at | workshop sewing && Elisa | liked | her work && Elisa | sewed | pretty dresses \"\n","s7 = \"Elisa | care | little brothers && Elisa | do | father's work && Elisa | prepare | bread every day && Elisa | bring bread | to customers \"\n","s8 = \"Elisa | educated at | Santiago's university && Elisa | career | education && Elisa | meet new friends | in her university classes && Elisa | best friend | Maria && Elisa | best friend | Laura \"\n","s9 = \"Elisa | started work | 20 years old && Elisa | worked in | textile factory && textile factory | location | Burgos \"\n","s10 = \"Elisa | like | festivals && Elisa | meet | Sergio && Sergio | ask Elisa | to dance && Elisa | fall in love with | Sergio && Elisa | started dating | Sergio \"\n","s11 = \"Elisa | bought a | shop in Santander && Elisa | set up a | sewing shop && Elisa | worked | hard \"\n","s12 = \"Elisa | marry | Sergio && Elisa | marry in | beautiful church in Santander && Elisa | had | 2 children && Elisa | son's name | Julio \""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ozTkhYVtopAT"},"outputs":[],"source":["s = [s00,s1,s2,s3,s4,s5,s6,s7,s8,s9,s10,s11,s12]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10581,"status":"ok","timestamp":1653817805212,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"S9c6sQiPqjMw","outputId":"2ca61893-7d8a-4188-f171-f8efb0bb5449"},"outputs":[{"name":"stdout","output_type":"stream","text":["<pad> Elisa was born in Lugo, Galicia on May 17th, 18.05.1937. His father's name is Juan and his name is Eva.</s>\n","<pad> Born in Santander, on November 1911, Juan was married to Eva, who worked as a seamstress. He served as a labrador.</s>\n","<pad> Elisa was born in La Salle, a school that was all-girl catholic. Her favorite school subjects are the drawing and her school was La Salle's school.</s>\n","<pad> Veronica is the best friend of Elisa, who played with friends and her favorite games are hide-and-seek. Elisa's best friend is Luis.</s>\n","<pad> Elisa died in 13 years old. She was a houseworker.</s>\n","<pad> Elisa was 15 years old and died of poverty.</s>\n","<pad> Elisa worked at the workshop sewing and she was sewed in pretty dresses.</s>\n","<pad> Elisa, who has a father's work, is a little brother of Elisa who is a baker who serves to customers.</s>\n","<pad> Elisa was a student at the Santiago's university and was best friends with Laura. Elisa is a professional in the education field. She was born in her university class.</s>\n","<pad> Elisa began her career in 20 years old and worked in the textile factory in Burgos.</s>\n","<pad> The musical genre of Elisa, who began her career in Sergio, is festivals. Sergio is a dancer.</s>\n","<pad> The Elisa was built in Santander and worked hard.</s>\n","<pad> Elisa was married to Sergio, who was born in Santander. She has 2 children and the son's name is Julio.</s>\n"]}],"source":["for sentence in s:\n","  print(to_sentence(sentence,model,do_sample = False, num_beams = 6, no_repeat_ngram_size = 4, num_beam_groups=3,\n","            min_length = 0, max_length = 75, top_k = 50, top_p = 0.92, temperature = 1,\n","            repetition_penalty = 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2840,"status":"ok","timestamp":1653819087001,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"kOJNUvygL2u1","outputId":"feff2dd8-f613-4036-f62f-32c65a4d30a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["<pad> Elisa was born in Lugo, Galicia on May 1937. His father's name is Juan and his name is Eva.</s>\n"]}],"source":["print(to_sentence(\n","    \"Elisa | birth place | Lugo, Galicia && Elisa | birth date | 18-05-1937 && Elisa | age | 82 && Elisa | father’s name | Juan && Elisa | mother’s name | Eva\",\n","    model,do_sample = False, num_beams = 18, no_repeat_ngram_size = 7, num_beam_groups=3,\n","            min_length = 0, max_length = 150, top_k = 50, top_p = 0.92, temperature = 1.0,\n","            repetition_penalty = 1.0))"]},{"cell_type":"markdown","metadata":{"id":"ApwY8krTYnrQ"},"source":["# Explicaciones de resultados"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":10427,"status":"ok","timestamp":1653837911744,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"DDbhoaMK68Yv","outputId":"cea28123-4c56-4826-a7f2-b43529bf818b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting bertviz\n","  Downloading bertviz-1.4.0-py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 5.1 MB/s \n","\u001b[?25hCollecting boto3\n","  Downloading boto3-1.23.10-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 50.4 MB/s \n","\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from bertviz) (0.1.96)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from bertviz) (2019.12.20)\n","Requirement already satisfied: transformers>=2.0 in /usr/local/lib/python3.7/dist-packages (from bertviz) (4.19.2)\n","Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from bertviz) (1.11.0+cu113)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bertviz) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from bertviz) (4.64.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->bertviz) (4.2.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (4.11.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (0.7.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (0.12.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (3.7.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.0->bertviz) (1.21.6)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=2.0->bertviz) (3.0.9)\n","Collecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n","Collecting botocore<1.27.0,>=1.26.10\n","  Downloading botocore-1.26.10-py3-none-any.whl (8.8 MB)\n","\u001b[K     |████████████████████████████████| 8.8 MB 50.0 MB/s \n","\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 7.3 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.27.0,>=1.26.10->boto3->bertviz) (2.8.2)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 57.6 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.27.0,>=1.26.10->boto3->bertviz) (1.15.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=2.0->bertviz) (3.8.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bertviz) (3.0.4)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 38.4 MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bertviz) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bertviz) (2022.5.18.1)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, bertviz\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed bertviz-1.4.0 boto3-1.23.10 botocore-1.26.10 jmespath-1.0.0 s3transfer-0.5.2 urllib3-1.25.11\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["urllib3"]}}},"metadata":{}}],"source":["!pip install bertviz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VHiR3wivY37Y"},"outputs":[],"source":["from transformers import utils\n","from bertviz import model_view\n","utils.logging.set_verbosity_error()  # Suppress standard warnings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VHXD8lblZclN"},"outputs":[],"source":["model_with_attention = model.from_pretrained(\"Modelo T5 Final/Modelos/webnlg/t5/t5_1epoch_30000examples\",output_attentions=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1653837929838,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"y4fQY2qBZugS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"51cb5ead-9e2a-4be6-b0fd-78716bcb2bd9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(32128, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",")"]},"metadata":{},"execution_count":9}],"source":["model_with_attention.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1653837929838,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"M39ae_UPn0N3","outputId":"58534fd0-1917-4b8b-d971-7d051c9a8c65"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(32128, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (2): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (3): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (4): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (5): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (6): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (7): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (8): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (9): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (10): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (11): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseReluDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (relu_act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",")"]},"metadata":{},"execution_count":10}],"source":["model_with_attention.to('cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gmrff9Pkmtdv"},"outputs":[],"source":["encoder_input_ids = tokenizer(\"WebNLG: Elisa | birth place | Lugo && Elisa | birth date | 18/05/1937 </s>\", return_tensors=\"pt\", add_special_tokens=True).input_ids\n","decoder_input_ids = tokenizer(\"Elisa was born in Lugo on May 1937. </s>\", return_tensors=\"pt\", add_special_tokens=True).input_ids\n","outputs = model_with_attention(input_ids=encoder_input_ids, labels=decoder_input_ids)\n","\n","encoder_text = tokenizer.convert_ids_to_tokens(encoder_input_ids[0])\n","decoder_text = tokenizer.convert_ids_to_tokens(decoder_input_ids[0])\n","tokens = tokenizer.convert_ids_to_tokens(encoder_input_ids[0]) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1N6rzSI3zg3N0qYuSi_sg75gfzuOtmBcV"},"executionInfo":{"elapsed":5247,"status":"ok","timestamp":1653837936298,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"},"user_tz":-120},"id":"8YLAwLoAmtbe","outputId":"899c8f18-d6fe-4b78-8c05-d4b79957c086"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["from bertviz import model_view\n","model_view(\n","    encoder_attention=outputs.encoder_attentions,\n","    decoder_attention=outputs.decoder_attentions,\n","    cross_attention=outputs.cross_attentions,\n","    encoder_tokens= encoder_text,\n","    decoder_tokens = decoder_text,\n","    include_heads=False,\n","    tokens = tokens,\n","    display_mode=\"light\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hkYKHT6CmtZf","colab":{"base_uri":"https://localhost:8080/","height":700,"output_embedded_package_id":"1VeiqiRQBa6Ax1AkqOfov3aLT2wqBisNo"},"executionInfo":{"status":"ok","timestamp":1653834882341,"user_tz":-120,"elapsed":29,"user":{"displayName":"MARÍA CRISTINA ALAMEDA SALAS","userId":"00427886758994799022"}},"outputId":"b5433367-1439-471c-fa9e-154899695a1b"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["from bertviz import head_view\n","attention = outputs[-1]  # Retrieve attention from model outputs\n","tokens = tokenizer.convert_ids_to_tokens(decoder_input_ids[0])  # Convert input ids to token strings\n","head_view(\n","    encoder_attention=outputs.encoder_attentions,\n","    decoder_attention=outputs.decoder_attentions,\n","    cross_attention=outputs.cross_attentions,\n","    encoder_tokens= encoder_text,\n","    decoder_tokens = decoder_text,\n","    tokens = tokens\n",")\n"]},{"cell_type":"code","source":[""],"metadata":{"id":"JXvUq9KVNCOz"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["hMe1hKshLgJn"],"name":"T5 FINAL.ipynb","provenance":[{"file_id":"1bNocmqOWIXTCVTWrMxugUIvPTsfipDGS","timestamp":1636967226724}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c4400c0814ff45fa93768fefa5f0050f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9773a33679c3421182825e469ab46dff","IPY_MODEL_f97b84d394784067b110e89aaf25fa22","IPY_MODEL_3ed8b3949bb940a6a4994e5b717f5f30"],"layout":"IPY_MODEL_2ba3e6d3aa19456db75abb6b17c2532a"}},"9773a33679c3421182825e469ab46dff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e36f8e17ab342898c367248e6c202e6","placeholder":"​","style":"IPY_MODEL_b4b92fe0866841cdaf7ae5a30b565b08","value":"Downloading: 100%"}},"f97b84d394784067b110e89aaf25fa22":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_56cf4b248f9c4c16880600a463a6d4d6","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2412b4fe120d4af8a3ba8837db18dfac","value":791656}},"3ed8b3949bb940a6a4994e5b717f5f30":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb62f4d0329a42fca113a58e039d21f0","placeholder":"​","style":"IPY_MODEL_8bf87df7ec6f44ffba43454ac1a354a4","value":" 773k/773k [00:00&lt;00:00, 1.25MB/s]"}},"2ba3e6d3aa19456db75abb6b17c2532a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e36f8e17ab342898c367248e6c202e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4b92fe0866841cdaf7ae5a30b565b08":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56cf4b248f9c4c16880600a463a6d4d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2412b4fe120d4af8a3ba8837db18dfac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eb62f4d0329a42fca113a58e039d21f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bf87df7ec6f44ffba43454ac1a354a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8cc660ae2b62436db2f91722286dd713":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_47863175f19c47f8ab4852d923d1dde7","IPY_MODEL_324cad3787e2488aa3843c63f986f082","IPY_MODEL_e637b44187f743bfbb93a08e7f17ea7f"],"layout":"IPY_MODEL_5b816b5c1bc04bd9984893a377a64470"}},"47863175f19c47f8ab4852d923d1dde7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16f92bbfeddc4d45902fecae8d26467e","placeholder":"​","style":"IPY_MODEL_5c812489bccf427e8de08ef368594b3f","value":"Downloading: 100%"}},"324cad3787e2488aa3843c63f986f082":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_44cfc2c2a1c645b98af5a51a315ec237","max":1199,"min":0,"orientation":"horizontal","style":"IPY_MODEL_89c1fcd926024b11a831b759c1d8f063","value":1199}},"e637b44187f743bfbb93a08e7f17ea7f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a82a948b584c4c588ae5abad8aaaeee1","placeholder":"​","style":"IPY_MODEL_8e0dce6bd31c48fcb30bd993f9a2ba5c","value":" 1.17k/1.17k [00:00&lt;00:00, 5.85kB/s]"}},"5b816b5c1bc04bd9984893a377a64470":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16f92bbfeddc4d45902fecae8d26467e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c812489bccf427e8de08ef368594b3f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44cfc2c2a1c645b98af5a51a315ec237":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89c1fcd926024b11a831b759c1d8f063":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a82a948b584c4c588ae5abad8aaaeee1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e0dce6bd31c48fcb30bd993f9a2ba5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ac8c90fa3ec4dd983c5e0724754c8a5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0f655c71aa524d328e83a7c0c8892af6","IPY_MODEL_7ee3776a658342f2be619c8b4acc4d2b","IPY_MODEL_08de41e27c734a7ab6c9fb2f32ceb8fa"],"layout":"IPY_MODEL_1c5214c0b1a947148f3b6e6ce21e6977"}},"0f655c71aa524d328e83a7c0c8892af6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf8070cafa06409e8fb7fbcdaeffbaff","placeholder":"​","style":"IPY_MODEL_536da5a33f7f4fb9a572d5bcd4be1c7d","value":"Downloading: 100%"}},"7ee3776a658342f2be619c8b4acc4d2b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_652c0dd7ebe74cc0a17394fc62eccc62","max":891691430,"min":0,"orientation":"horizontal","style":"IPY_MODEL_23852c2717f543d898872943e946d40a","value":891691430}},"08de41e27c734a7ab6c9fb2f32ceb8fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79e25a4c2fb24ddd873fa4c0b385533e","placeholder":"​","style":"IPY_MODEL_9dac17bd291046d88f4e18f56a236154","value":" 850M/850M [00:41&lt;00:00, 49.9MB/s]"}},"1c5214c0b1a947148f3b6e6ce21e6977":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf8070cafa06409e8fb7fbcdaeffbaff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"536da5a33f7f4fb9a572d5bcd4be1c7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"652c0dd7ebe74cc0a17394fc62eccc62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23852c2717f543d898872943e946d40a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"79e25a4c2fb24ddd873fa4c0b385533e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9dac17bd291046d88f4e18f56a236154":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}