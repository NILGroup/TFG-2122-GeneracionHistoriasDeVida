{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers and Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, importamos GPT2LMHeadModel para la generatción de texto y GPT2Tokenizer como tokenizer del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, cargamos el tokenizer y se lo pasamos al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 620/620 [00:00<00:00, 74.7kB/s]\n",
      "Downloading: 100%|██████████| 817/817 [00:00<00:00, 145kB/s]\n",
      "Downloading: 100%|██████████| 830k/830k [00:06<00:00, 134kB/s]\n",
      "Downloading: 100%|██████████| 496k/496k [00:02<00:00, 248kB/s]\n",
      "Downloading: 100%|██████████| 387/387 [00:00<00:00, 141kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [40, 2261, 1327], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"datificate/gpt2-small-spanish\") \n",
    "\n",
    "tokenizer('Hola mundo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crist\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\transformers\\models\\auto\\modeling_auto.py:660: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "Downloading: 100%|██████████| 487M/487M [00:42<00:00, 12.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelWithLMHead.from_pretrained(\"datificate/gpt2-small-spanish\" , pad_token_id = tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después, para generar el texto, añadimos un primer texto a nuestro modelo y después a partir de él, generamos el texto. Antes de todo tenemos que preprocesar (tokenizar) ese primer texto que pasamos al modelo.\n",
    "\n",
    "\n",
    "'pt' significa PyTorch Tensors\n",
    "\n",
    "Con endode pasamos de texto a números y con decode pasamos de números a texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"La sequía es un problema en nuestros días.\"\n",
    "input_ids = tokenizer.encode(texto,return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  552, 20236,   293,   298,  4064,   278,  9993,  1692,    14]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La sequía es un problema en nuestros días.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar, generamos el texto a partir del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(input_ids, \n",
    "    max_length = 200, \n",
    "    num_beams = 5,\n",
    "    no_repeat_ngram_size  = 2,\n",
    "    early_stopping = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La sequía es un problema en nuestros días. La sequía puede ser causada por la falta de agua en el suelo, o por el exceso de humedad en la atmósfera.\\n\\nEl agua que fluye a través de la superficie del suelo es el agua de lluvia, que se encuentra en las zonas más secas del planeta. El agua se evapora y se convierte en dióxido de carbono (CO), que es utilizado como combustible para la agricultura, la industria y el transporte de energía. Los gases de efecto invernadero (H2O) son el principal causa de las emisiones de CO, por lo que la mayoría de los seres humanos se alimentan de ellos. Por lo tanto, el CO es una fuente importante de contaminación del aire, ya que causa que el aire se descomponga en partículas de polvo, polvo y agua. En el caso del agua, las partículas son absorbidas por las plantas y los animales, y son transportadas al medio ambiente, donde se convierten en CO. Las partículas también se transportan'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f993294f222aa43e7d2ef032cb7262ce65d4bb70d5d6a0b5429ac56c13f0bb1e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
